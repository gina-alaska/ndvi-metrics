Calculation Processes for NDVI Metrics
Version1.1
Jiang zhu
jiang@gina.alaska.edu
2011/5/3
	This document describes the NDVI metrics algorithms and running environment of these programs. Programs are realized by IDL codes. 
A. Directories and IDL startup file
The programs are resided in jzhu.gina.alaska.edu. The directories used to store different programs or data files are:
1. nps-cesu home directory: CESU_NDVI=~/nps/cesu/modis_ndvi_250m
2. directory for scripts: $CESU_NDVI/script
 unzip_ndvi.bash, and rename_ndvi.bash are stored here.
3. work directory: $CESU_NDVI/wrkdir 
store unziped data files,immediate data files, and result data files.
4. idl programs directory: $CENSU_NDVI/wrkdir/ndvi_nps
You need set environment variable
Export IDL_STARTUP=/home/jiang/nps/cesu/startup_env.pro

In startup_env.pro, you put one idl command to start envi:
ENVI, /RESTORE_BASE_SAVE_FILES
5. raw zip ndvi data directory: ~/nps/cesu/modis_ndvi_250m/TERRA

     B. The procedure of the data process: 
           1. unzip the ndvi files (~nps/cesu/script)
           The ndvi files come from EMODIS website. They are zip files. First, download them and store them   ~/nps/cesu/modis_ndvi_250m/TERRA. Then unzip and rename them by using scripts "unzip_ndvi.bash" and "rename_ndvi.bash", respectively.
      2. stack and subset 7-day ndvi data, and mark those pixels which are not suitable for NDVI metrics calculation.    
      inputs: flist_ndvi, flist_bq
      flist_ndvi includes 7-day ndvi file names of one year. flist_bq includes 7-day ndvi_bq file names of the same year.
 	program:  oneday.pro
   	subroutines: start_batch.pro, oneyear_data_layer_subset_good.pro,
read_ndvi.pro, subset.pro
      outputs: yyyy_oneyear_layer_stack_0_200_snow_cloud_n4000. This is stacked, subset, and good data file.       
 
      3. stack three years of one-year data into a multiple-year (three years) data
  	inputs: oneyear-file-list
           The oneyear-file-list includes file names of one-year good data files.
   	program: layer_stack.pro
       	subroutines: start_batch.pro
  	output: yyyy_multiyear_layer_stack_0_200_snow_cloud_n4000. This is a multiple year (normally 3 years) stacked data file.
      4. calculate one-year metrics
      inputs: a multiple-year data file
 	program: smooth_calculate_metrics_tile.pro
          subroutines: start_batch.pro, time_series_process.pro,  interpol_noextension_vector.pro, cutoff_interp.pro, user_metrics.pro, wls_smooth.pro 
      outputs: a metrics data file and a smoothed data file.
C. list of the program files 
smooth_calculate_metrics_tile.pro, smooth_calculate_metrics.pro, layer_stack.pro, oneyear.pro, oneyear_data_layer_subset_good.pro, interpol_noextension_vector.pro, read_ndvi.pro, start_batch.pro, subset.pro, user_metrics.pro, cutoff_interp.pro, wls_smooth.pro, startup_env.pro

D. data format description
1. The raw data comes from EMODIS. I use two kinds of files to produce ndvi metrics. One is 250m_compisit_ndvi.tif and other is 250m_composit_ndvi_bq.tif. The data range in ndvi.tif is -1999 to 10,000, -2000 is fill value, and the scale factor is 0.0001. Data in ndvi_bq.tif includes flag information. It indicates the type of the pixels. Types of the pixels are cloud, snow, fog, etc.
2. First, we process one pair of ndvi and ndvi_bq files by getting rid of those cloud, snow, fog, bad quality, negative reflectance pixels by filling these pixels with another fill value of -4000. Then we convert the data into 0 to 200 byte data by using the formula y=byte(x/100.0+100).In the new data, valid ndvi values are in the range of 100 to 200. The fill values (-2000) are converted into 80, and cloud, snow, fog pixels in raw data are converted into 60.
3. Stack one weekly data into a one year data file. The result file is named as yyyy_one_year_subset_good.tif (data range is 0 to 200, and data include 42 bands).
4. Combine the year before, the year, and the year after data files into a multiple-year data file. The program layer_stack.pro finishes this process and produced a 3-year stacked data file named yyyy_multiyear_stack_stack_0_200_set_snow_cloud_n4000.hdr (data range is 0 to 200, and data include 42 bands).
5. Smooth the multiple year stacked data and calculate the metrics of the year. The result data file is named as yyyy_multiyear_layer_stack_0_200_set_snow_cloud_n4000_smooth.hdr (data range is 0 to 200), and the metrics data is named as yyyy_multiyear_layer_stack_metrics_not_0_200_set_snow_cloud_n2000.hdr (data include 12 bands)
E. detailed description of the algorithms
In the whole process of NDVI metrics calculation, three core algorithms are: bad pixel elimination, time-series smooth, and time-series NDVI metric calculation.
1. Bad pixel elimination
"read_ndvi.bash" does bad pixel elimination. 
a. It reads one pair of file (a ndvi file and its related ndvi quality file) into memory. Ndvi data are stored in data1(ns,nl), and ndvi quality flag data are stored in data2(ns,nl). 
b. stack the data1 and data2 together to form a two bands data(ns,nl,2). Band1 are data1 and band2 are data2. 
c. goes through every pixel of data. First, if pixel is cloud, snow, bad quality, or negative reflectance, set the pixel value (band 1) to -4000, otherwise, keep the pixel value. Second, convert the value of the pixel from range -4000 to 10,000 (integer) into range 0 to 200 (byte) by using equation out=byte(in/100 +100). 
d. output the band1 of the data. In the output data, snow, cloud, bad quality, or negative reflectance pixels have byte value of 60b (b presents data type is byte), filling pixels have byte value of 80b, good ndvi pixels have byte values in the range from 100b to 200b.  
2. time-series smooth algorithms 
"interpol_nonextension_vector.pro" and "wls_smooth.pro" do smooth for time-series vector. The program “interpol_nonextension_vector.pro” calls the subroutine named “cutoff_interp.pro” to get rid of the points which are fill points, replace snow and cloud (with value of 60b) pixels with value 101b or 102b, and interpolate the time-series vector. Wls_smooth.pro does smooth algorithm.  Figure1. Smooth Algorithm Flowchart describes how to do smooth for a time-series vector.
                   
Figure1. Flowchart of Smooth Algorithm
3. NDVI metrics algorithm
“user_metrics.pro” does metrics calculation for a smoothed vector. It accepts raw vector, smoothed vector, band name vector. It outputs metrics vector. The main steps are: Step a, Check the data in smoothed vector to make sure they are suitable to calculate metrics. If the values of the points are the same, this means the pixel is not suitable for ndvi metrics calculation. Set the flag in output metrics vector, then return. If the index of the maximum value is outside of reasonable range, we also do not calculate the metrics, set flag=0, and return.  Step b, after the smoothed_v passes the tests in step a, we retrieve onset index and end-of-greenness index. First, we retrieve onset index. We calculate three possible indices: idx_max_dev, the index of the maximum value in the derivative of smoothed_v; idx_max_dediff, the index of the maximum value in the derivative of the difference between smoothed_v and backaward moving average (diff); idx_cross, the index where the values in diff change from negative to positive. Then we decide which index is the onset-idx by comparison of the three indices. We use thre similar method toretrieve the end-of-greenness index. Step c, after we get onset_idx and end-of-greenness idx, we can easily calculate other metrics items.  Figure 2 is the flowchart for NDVI metrics algorithm. 








Figure 2 NDVI Metrics Algorithm Flowchart







  

